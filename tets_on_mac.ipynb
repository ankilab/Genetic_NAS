{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from get_datasets.Get_Datasets import get_data_array, get_datasets\n",
    "from src.Train_Model import train_model\n",
    "from src.Create_Model import create_model\n",
    "from src.Evolutionary_Algorithm import create_next_population, create_first_population, select_best_2_model, start_evolution\n",
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "batch_size = 64\n",
    "auto = tf.data.AUTOTUNE\n",
    "resize_bigger = 280\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "def preprocess_dataset(is_training=True):\n",
    "    def _pp(image, label):\n",
    "        if is_training:\n",
    "            # Resize to a bigger spatial resolution and take the random\n",
    "            # crops.\n",
    "            image = tf.image.resize(image, (resize_bigger, resize_bigger))\n",
    "            image = tf.image.random_crop(image, (image_size, image_size, 3))\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "        else:\n",
    "            image = tf.image.resize(image, (image_size, image_size))\n",
    "        label = tf.one_hot(label, depth=num_classes)\n",
    "        return image, label\n",
    "\n",
    "    return _pp\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset, is_training=True):\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(batch_size * 10)\n",
    "    dataset = dataset.map(preprocess_dataset(is_training), num_parallel_calls=auto)\n",
    "    return dataset.batch(batch_size).prefetch(auto)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 3303\n",
      "Number of validation examples: 367\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = tfds.load(\n",
    "    \"tf_flowers\", split=[\"train[:90%]\", \"train[90%:]\"], as_supervised=True\n",
    ")\n",
    "\n",
    "num_train = train_dataset.cardinality()\n",
    "num_val = val_dataset.cardinality()\n",
    "print(f\"Number of training examples: {num_train}\")\n",
    "print(f\"Number of validation examples: {num_val}\")\n",
    "\n",
    "train_dataset = prepare_dataset(train_dataset, is_training=True)\n",
    "val_dataset = prepare_dataset(val_dataset, is_training=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m population_array, fitness_history, a, b \u001B[38;5;241m=\u001B[39m \u001B[43mstart_evolution\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_ds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_ds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpopulation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Genetic_NAS\\src\\Evolutionary_Algorithm.py:179\u001B[0m, in \u001B[0;36mstart_evolution\u001B[1;34m(train_ds, val_ds, test_ds, generations, population, num_classes, epochs, population_array)\u001B[0m\n\u001B[0;32m    176\u001B[0m     population_array \u001B[38;5;241m=\u001B[39m create_first_population(population\u001B[38;5;241m=\u001B[39mpopulation, num_classes\u001B[38;5;241m=\u001B[39mnum_classes)\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(generations):\n\u001B[1;32m--> 179\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGenerations: \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mgenerations\u001B[49m)\n\u001B[0;32m    180\u001B[0m     a, b, max_fitness \u001B[38;5;241m=\u001B[39m select_best_2_model(train_ds, val_ds, test_ds, population_array, epochs\u001B[38;5;241m=\u001B[39mepochs, num_classes\u001B[38;5;241m=\u001B[39mnum_classes)\n\u001B[0;32m    181\u001B[0m     population_array \u001B[38;5;241m=\u001B[39m create_next_population(a, b, population\u001B[38;5;241m=\u001B[39mpopulation, num_classes\u001B[38;5;241m=\u001B[39mnum_classes)\n",
      "\u001B[1;31mTypeError\u001B[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "population_array, fitness_history, a, b = start_evolution(train_ds=train_dataset, val_ds=val_dataset, test_ds=val_dataset, generations=16, population=16, num_classes=5, epochs=20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(fitness_history)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
